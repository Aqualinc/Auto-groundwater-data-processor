
title: "R Notebook to combine APP piezometer data files into a single file"
output: html_notebook
---
Project WL20023 Christchurch City Council APP..
Prepared by Tim Kerr, Rainfall.NZ for Aqualinc.
March 2020

Background
Christchurch City Council have a large number of piezometers measuring groundwater levels at short intervals (10 minutes).
These piezometers are downloaded intermittantly.
Its helpfull to stitch the data together after each download.

********** There is an issue with the am/pm formatting. This needs to be manually checked each time.
This could be turned into a function which accepted Old directory, and new directory, and save directory, and magic could then happen.

#After updating, need to go through and delete all the shorter files of the duplicated APP sites, i.e. the ones that have been updated.

```{r}
if (!require(zoo)) install.packages("zoo"); library(zoo)
if (!require(lubridate)) install.packages("lubridate"); library(lubridate)

AllDataDirectory <- "G:\\WL Projects\\WL20023_CCC APP\\AllData"
LatestDataDirectory <- "G:\\WL Projects\\WL20023_CCC APP\\For ECan April-May 2021\\April-May Download Run\\April-May Data 2021\\BaroAndOffsetCorrected"

#For testing on Tims Laptop
#LatestDataDirectory <- "D:\\Projects\\Aqualinc\\projects\\APP\\Data\\Data Harvest 202106\\BaroAndOffsetCorrected"

SaveDataDirectory <- AllDataDirectory
  #SaveDataDirectory <- "G:\\WL Projects\\WL20023_CCC APP\\AllData"

#Prepare a list of all the APP numbers

#Get a file list from the download data directories
DownloadFileNames <- list.files(path=c(AllDataDirectory,LatestDataDirectory),pattern="^APP[0-9]{4}_[0-9]{8}-[0-9]{8}\\.csv",full.names = TRUE)

#Parse the file names to give just the APP numbers.
APPNumbers <- as.numeric(sub(pattern="^APP([0-9]*)_.*csv","\\1",x=basename(DownloadFileNames)))

#Get just the unique APP numbers which have duplicates, these are the ones that need updating
APPNumbersToUpdate <- APPNumbers[duplicated(APPNumbers)]

#Concatenate the download files for each site writing a new file for each one as we go
for (APPNumber in APPNumbersToUpdate) { #APPNumber <- 5
  #Get the filenames associated with that APP number, but don't use the "initial_QA" files 
  #as in at least one case (APP 5), the initial_QA and the first proper download 
  #have the same time, but different values in the data.
  
  print(paste("Processing APP number",APPNumber))
  FileIndices <- which(APPNumbers == APPNumber)
  
  GWFiles <- DownloadFileNames[FileIndices]
  
  #load these files without headers, stick them together, and then stick them in the complete file, 
  #removing any duplicate date-time entries.
  #There are two types of files, Aqualinc formatted (which has a filename that starts with "APP") 
  #and T&T formatted. Aqualinc has a single header line. T&T has 12 header lines.
  #Additionally, T&T don't invert their levels, but Aqualinc do.
  InputDataLists <- lapply(GWFiles, function(FileOfInterest) {  #FileOfInterest <- GWFiles[1]
    if(substring(basename(FileOfInterest),1,3) == "APP") {
      SkipLines <- 0
      LevelsMultiplier <- 1
    }else {
      SkipLines = 11
      LevelsMultiplier <- -1
    }
    GroundwaterRawData <- read.csv(FileOfInterest, stringsAsFactors = FALSE,skip = SkipLines)
    GroundwaterRawData$LEVEL <- GroundwaterRawData$LEVEL * LevelsMultiplier
    return(GroundwaterRawData[,c("Date","Time","LEVEL","TEMPERATURE")])
  } )
  #browser()
  InputDataCombined <- do.call("rbind", InputDataLists)
  
  #It seems the locale is different from machine to machine. I have locale on my 
  #laptop set to "English_New zealand.1252" which has the am/pm format as am/pm or AM/PM, 
  #but NOT a.m./p.m.. So completely different to what was working at Aqualinc! 
  #I haven't checked the Aqualinc locale yet.
  
  #I need to get the date and time in order, so turn it into a zoo time series object 
  #using the date and time columns to build the index
  #There is this annoying thing where am and pm are not recognsed but a.m. and p.m. are. 
  #Apparently this is a "locale" thing.
  #So i need to replace the am's with a.m. and the pm's with p.m.
  #
  #InputDataCombined$Time <- sub("am","a.m.",InputDataCombined$Time)
  #InputDataCombined$Time <- sub("pm","p.m.",InputDataCombined$Time)
  #InputDataCombined$Time <- sub("AM","a.m.",InputDataCombined$Time)
  #InputDataCombined$Time <- sub("PM","p.m.",InputDataCombined$Time)
  
  InputDataCombined$Time <- sub("a.m.","am",InputDataCombined$Time)
  InputDataCombined$Time <- sub("p.m.","pm",InputDataCombined$Time)
  
  
  #Even more annoyingly, the time is not in a consistent format between files, 
  #sometimes it has the am/pm sometimes it has a 24 hour time.
  #So I need to convert both types and stick them together.
  #But note that the 24 hour format still converts the am/pm format (and gets it wrong), 
  #but the am/pm format returns an NA for the 24 hour format as it can't find the am/pm characters. 
  #So I do both conversions, and then swap out the NA values from the am/pm attempt 
  #with the 24 hour versions. This assumes everything that is not in am/pm format is in 24 hour format.
  
  DateTimeA <- as.POSIXct(paste(InputDataCombined$Date,InputDataCombined$Time),
                          format="%d/%m/%Y %I:%M:%S %p",origin="1970-01-01",tz="Etc/GMT-12")
  DateTimeB <- as.POSIXct(paste(InputDataCombined$Date,InputDataCombined$Time),
                          format="%d/%m/%Y %H:%M:%S",origin="1970-01-01",tz="Etc/GMT-12")
  DateTimeA[is.na(DateTimeA)] <- DateTimeB[is.na(DateTimeA)] # Combine both while keeping their ranks
  
  InputDataCombined$DateTime <- DateTimeA
  #InputDataCombined$DateTime <- as.POSIXct(paste(InputDataCombined$Date,InputDataCombined$Time),
  #                         format="%d/%m/%Y %I:%M:%S %p",origin="1970-01-01",tz="Etc/GMT-12")
  
  #Remove duplicates
  InputDataCombinedNoDuplicates <- InputDataCombined[!duplicated(InputDataCombined$DateTime,fromLast=TRUE),]
  
  #Re-order based on time
  InputDataCombinedNoDuplicates <- InputDataCombinedNoDuplicates[order(InputDataCombinedNoDuplicates$DateTime),]
  
  #Make the Time column format consistent for all records/rows
  InputDataCombinedNoDuplicates$Time <- format(InputDataCombinedNoDuplicates$DateTime,"%H:%M:%S")
  
  #Remove any lines with NA DateTimes
  InputDataCombinedNoDuplicates <- InputDataCombinedNoDuplicates[!is.na(InputDataCombinedNoDuplicates$DateTime),]
  
  #Export it all to a new csv
  StartDate <- format(min(InputDataCombinedNoDuplicates$DateTime,na.rm=TRUE),"%Y%m%d")
  EndDate <- format(max(InputDataCombinedNoDuplicates$DateTime,na.rm=TRUE),"%Y%m%d")
  CombinedFilename <- paste0("APP",formatC(APPNumber,width=4,flag="0"),"_",StartDate,"-",EndDate,".csv")
  write.table(InputDataCombinedNoDuplicates[,c("Date","Time","LEVEL","TEMPERATURE")],
              file.path(SaveDataDirectory,CombinedFilename),quote=FALSE,row.names = FALSE,sep=",")
}
```