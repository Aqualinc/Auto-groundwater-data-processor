---
title: "R Notebook to estimate the sensor levels in the EQC shallow groundwater network"
output: html_notebook
---

I am able to correct the EQC groundwater pressure sensor data for air pressure variations.
To convert the compensated values to "depth to groundwater" I need to know the depth of the sensor within the well.
This data have not yet been provided by T&T so this script has been prepared to back-calculate it.

Adding my compensated values with the T&T processed groundwater levels should give me the sensor depth.

Start by creating a pile of Compensated files from the first data harvest
```{r}
#Load my functions and any libraries that I may need
source("\\\\aqualinc-sbs\\data\\ARL Projects\\WL Projects\\WL18036_EQC Earthquake Commission\\R\\Auto-groundwater-data-processor\\GWProcessingFunctions.R")


#Set some directories and filenames
DataDirectory <- "G:\\ARL Projects\\WL Projects\\WL18036_EQC Earthquake Commission\\Data\\HighResolutionData\\FromT_T_January2019\\DH1 - DH4\\DH1-DH4 Raw"
OutputDataDirectory <- "G:\\ARL Projects\\WL Projects\\WL18036_EQC Earthquake Commission\\Data\\HighResolutionData"

```


Create a big pile of compensated files from Data Harvest 1
```{r}
#Get the barometric data
BaroData <- BaroDataMerging(file.path(DataDirectory,"Data Harvest 1"))

#Set the directory for the T&T compensated data
CompDataDirectory <- "G:\\ARL Projects\\WL Projects\\WL18036_EQC Earthquake Commission\\Data\\HighResolutionData\\Combined_Sept16_Sept18"

#Get a list of the files to use
FilesToProcess <- list.files(path = file.path(DataDirectory,"Data Harvest 1"), pattern = '[1-9][0-9,_]*\\.xle$', recursive = TRUE, full.names = TRUE)

#Divide into groups of 10
GroupedFiles <- split(FilesToProcess, ceiling(seq_along(FilesToProcess)/10))


SensorLevels <- lapply(GroupedFiles[1:2], function(OneGroup) {
  #Read in the group
  RawData <- lapply(OneGroup, ReadXMLData)
  
  SingleGroupSensorLevels <- sapply(RawData, function(SingleSite) {
    
    APPNo <- SingleSite[['APP']]
    print(APPNo)
    Zone <- SingleSite[['Zone']]
    
    BaroCorrectedData <- BarometricCorrection(SingleSite[[1]]$'Depth',BaroData[[Zone]])
    
    #Find the T&TCompensated data for the same site
    TandTFile <- list.files(path = CompDataDirectory, pattern = paste0("^APP",sprintf("%04d", APPNo),"_[0-9,-]*\\.csv$"), full.names = TRUE)
    
    #Load the T&T Compensated data as a zoo
    TandTData <- read.csv(TandTFile, stringsAsFactors = FALSE)
    
    #Turn into a zoo
    TandTZoo <- zoo(TandTData$LEVEL,order.by= as.POSIXct(paste(TandTData$Date,TandTData$Time),format="%d/%m/%Y %I:%M:%S %p",tz="Etc/GMT-12"))
    
    #Merge the BaroCorrected with the TandTData
    Merged <- merge(BaroCorrectedData,TandTZoo)
    
    SensorDepth <- rowSums(Merged)

    #Get rid of any rows where both data are not available
    SensorDepth <- SensorDepth[complete.cases(SensorDepth)]
    
    #get the average
    MeanSensorDepth <- mean(SensorDepth)
    
    #Get the standard deviation just so it can be reported
    SDSensorDepth <- sd(SensorDepth)
    
    #Report the APP number, average sensor depth and SD of the sensor depth
    print(paste("APPNo:",APPNo, "has a sensor depth of", MeanSensorDepth,"m with a standard deviation of",SDSensorDepth)  )

    names(MeanSensorDepth) <- paste0("APP",APPNo)
    return(MeanSensorDepth)
  })
})
AllSensorLevels <- do.call(c,unname(SensorLevels))

#write this information to a file for later use
write.table(cbind(names(AllSensorLevels),round(AllSensorLevels,2)), file = file.path(OutputDataDirectory,"SensorLevels.csv"),quote=FALSE,sep=",",col.names = c("APPNo","DepthToSensor(m)"),row.names=FALSE)
```



This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
